{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7230081,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport gc\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import cross_val_score, cross_validate\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.ensemble import VotingRegressor\n\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-12-08T00:17:52.887098Z","iopub.execute_input":"2023-12-08T00:17:52.887558Z","iopub.status.idle":"2023-12-08T00:17:52.894261Z","shell.execute_reply.started":"2023-12-08T00:17:52.887524Z","shell.execute_reply":"2023-12-08T00:17:52.892964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks to [@greysky](https://www.kaggle.com/greysky) for the data pre-processing work in his notebook [Enefit Generic Notebook](https://www.kaggle.com/code/greysky/enefit-generic-notebook/notebook).","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\nclass MonthlyKFold:\n    def __init__(self, n_splits=3):\n        self.n_splits = n_splits\n        \n    def split(self, X, y, groups=None):\n        dates = 12 * X[\"year\"] + X[\"month\"]\n        timesteps = sorted(dates.unique().tolist())\n        X = X.reset_index()\n        \n        for t in timesteps[-self.n_splits:]:\n            idx_train = X[dates.values < t].index\n            idx_test = X[dates.values == t].index\n            \n            yield idx_train, idx_test\n            \n    def get_n_splits(self, X, y, groups=None):\n        return self.n_splits\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:17:54.027487Z","iopub.execute_input":"2023-12-08T00:17:54.027878Z","iopub.status.idle":"2023-12-08T00:17:54.035413Z","shell.execute_reply.started":"2023-12-08T00:17:54.027848Z","shell.execute_reply":"2023-12-08T00:17:54.034276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\ndef feature_eng(df_data, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target):\n    df_data = (\n        df_data\n        .with_columns(\n            pl.col(\"datetime\").cast(pl.Date).alias(\"date\"),\n        )\n    )\n    \n    df_client = (\n        df_client\n        .with_columns(\n            (pl.col(\"date\") + pl.duration(days=2)).cast(pl.Date)\n        )\n    )\n    \n    df_gas = (\n        df_gas\n        .rename({\"forecast_date\": \"date\"})\n        .with_columns(\n            (pl.col(\"date\") + pl.duration(days=1)).cast(pl.Date)\n        )\n    )\n    \n    df_electricity = (\n        df_electricity\n        .rename({\"forecast_date\": \"datetime\"})\n        .with_columns(\n            pl.col(\"datetime\") + pl.duration(days=1)\n        )\n    )\n    \n    df_location = (\n        df_location\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32)\n        )\n    )\n    \n    df_forecast = (\n        df_forecast\n        .rename({\"forecast_datetime\": \"datetime\"})\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            pl.col('datetime').dt.convert_time_zone(\"Europe/Bucharest\").dt.replace_time_zone(None).cast(pl.Datetime(\"us\")),\n        )\n        .join(df_location, how=\"left\", on=[\"longitude\", \"latitude\"])\n        .drop(\"longitude\", \"latitude\")\n    )\n    \n    df_historical = (\n        df_historical\n        .with_columns(\n            pl.col(\"latitude\").cast(pl.datatypes.Float32),\n            pl.col(\"longitude\").cast(pl.datatypes.Float32),\n            pl.col(\"datetime\") + pl.duration(hours=37)\n        )\n        .join(df_location, how=\"left\", on=[\"longitude\", \"latitude\"])\n        .drop(\"longitude\", \"latitude\")\n    )\n    \n    df_forecast_date = (\n        df_forecast\n        .group_by(\"datetime\").mean()\n        .drop(\"county\")\n    )\n    \n    df_forecast_local = (\n        df_forecast\n        .filter(pl.col(\"county\").is_not_null())\n        .group_by(\"county\", \"datetime\").mean()\n    )\n    \n    df_historical_date = (\n        df_historical\n        .group_by(\"datetime\").mean()\n        .drop(\"county\")\n    )\n    \n    df_historical_local = (\n        df_historical\n        .filter(pl.col(\"county\").is_not_null())\n        .group_by(\"county\", \"datetime\").mean()\n    )\n    \n    df_data = (\n        df_data\n        .join(df_gas, on=\"date\", how=\"left\")\n        .join(df_client, on=[\"county\", \"is_business\", \"product_type\", \"date\"], how=\"left\")\n        .join(df_electricity, on=\"datetime\", how=\"left\")\n        \n        .join(df_forecast_date, on=\"datetime\", how=\"left\", suffix=\"_fd\")\n        .join(df_forecast_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_fl\")\n        .join(df_historical_date, on=\"datetime\", how=\"left\", suffix=\"_hd\")\n        .join(df_historical_local, on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hl\")\n        \n        .join(df_forecast_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_fdw\")\n        .join(df_forecast_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_flw\")\n        .join(df_historical_date.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=\"datetime\", how=\"left\", suffix=\"_hdw\")\n        .join(df_historical_local.with_columns(pl.col(\"datetime\") + pl.duration(days=7)), on=[\"county\", \"datetime\"], how=\"left\", suffix=\"_hlw\")\n        \n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=2)).rename({\"target\": \"target_1\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=3)).rename({\"target\": \"target_2\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=4)).rename({\"target\": \"target_3\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=5)).rename({\"target\": \"target_4\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=6)).rename({\"target\": \"target_5\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=7)).rename({\"target\": \"target_6\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        .join(df_target.with_columns(pl.col(\"datetime\") + pl.duration(days=14)).rename({\"target\": \"target_7\"}), on=[\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"datetime\"], how=\"left\")\n        \n        .with_columns(\n            pl.col(\"datetime\").dt.ordinal_day().alias(\"dayofyear\"),\n            pl.col(\"datetime\").dt.hour().alias(\"hour\"),\n            pl.col(\"datetime\").dt.day().alias(\"day\"),\n            pl.col(\"datetime\").dt.weekday().alias(\"weekday\"),\n            pl.col(\"datetime\").dt.month().alias(\"month\"),\n            pl.col(\"datetime\").dt.year().alias(\"year\"),\n        )\n        \n        .with_columns(\n            pl.concat_str(\"county\", \"is_business\", \"product_type\", \"is_consumption\", separator=\"_\").alias(\"category_1\"),\n        )\n        \n        .with_columns(\n            (np.pi * pl.col(\"dayofyear\") / 183).sin().alias(\"sin(dayofyear)\"),\n            (np.pi * pl.col(\"dayofyear\") / 183).cos().alias(\"cos(dayofyear)\"),\n            (np.pi * pl.col(\"hour\") / 12).sin().alias(\"sin(hour)\"),\n            (np.pi * pl.col(\"hour\") / 12).cos().alias(\"cos(hour)\"),\n        )\n        \n        .with_columns(\n            pl.col(pl.Float64).cast(pl.Float32),\n        )\n        \n        .drop(\"date\", \"datetime\", \"hour\", \"dayofyear\")\n    )\n    \n    return df_data\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:17:54.858750Z","iopub.execute_input":"2023-12-08T00:17:54.859486Z","iopub.status.idle":"2023-12-08T00:17:54.883934Z","shell.execute_reply.started":"2023-12-08T00:17:54.859447Z","shell.execute_reply":"2023-12-08T00:17:54.882728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\ndef to_pandas(X, y=None):\n    cat_cols = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", \"category_1\"]\n    \n    if y is not None:\n        df = pd.concat([X.to_pandas(), y.to_pandas()], axis=1)\n    else:\n        df = X.to_pandas()    \n    \n    df = df.set_index(\"row_id\")\n    df[cat_cols] = df[cat_cols].astype(\"category\")\n    \n    df[\"target_mean\"] = df[[f\"target_{i}\" for i in range(1, 7)]].mean(1)\n    df[\"target_std\"] = df[[f\"target_{i}\" for i in range(1, 7)]].std(1)\n    df[\"target_ratio\"] = df[\"target_6\"] / (df[\"target_7\"] + 1e-3)\n    \n    return df\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:17:55.803661Z","iopub.execute_input":"2023-12-08T00:17:55.804073Z","iopub.status.idle":"2023-12-08T00:17:55.811741Z","shell.execute_reply.started":"2023-12-08T00:17:55.804040Z","shell.execute_reply":"2023-12-08T00:17:55.810494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\ndef lgb_objective(trial):\n    params = {\n        'n_iter'           : 1000,\n        'verbose'          : -1,\n        'random_state'     : 42,\n        'objective'        : 'l2',\n        'learning_rate'    : trial.suggest_float('learning_rate', 0.01, 0.1),\n        'colsample_bytree' : trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        'colsample_bynode' : trial.suggest_float('colsample_bynode', 0.5, 1.0),\n        'lambda_l1'        : trial.suggest_float('lambda_l1', 1e-2, 10.0),\n        'lambda_l2'        : trial.suggest_float('lambda_l2', 1e-2, 10.0),\n        'min_data_in_leaf' : trial.suggest_int('min_data_in_leaf', 4, 256),\n        'max_depth'        : trial.suggest_int('max_depth', 5, 10),\n        'max_bin'          : trial.suggest_int('max_bin', 32, 1024),\n    }\n    \n    model  = lgb.LGBMRegressor(**params)\n    X, y   = df_train.drop(columns=[\"target\"]), df_train[\"target\"]\n    cv     = MonthlyKFold(1)\n    scores = cross_val_score(model, X, y, cv=cv, scoring='neg_mean_absolute_error')\n    \n    return -1 * np.mean(scores)\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:17:56.505204Z","iopub.execute_input":"2023-12-08T00:17:56.506243Z","iopub.status.idle":"2023-12-08T00:17:56.513685Z","shell.execute_reply.started":"2023-12-08T00:17:56.506195Z","shell.execute_reply":"2023-12-08T00:17:56.512670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Global Variables","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\nroot = \"/kaggle/input/predict-energy-behavior-of-prosumers\"\n\ndata_cols        = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime', 'row_id']\nclient_cols      = ['product_type', 'county', 'eic_count', 'installed_capacity', 'is_business', 'date']\ngas_cols         = ['forecast_date', 'lowest_price_per_mwh', 'highest_price_per_mwh']\nelectricity_cols = ['forecast_date', 'euros_per_mwh']\nforecast_cols    = ['latitude', 'longitude', 'hours_ahead', 'temperature', 'dewpoint', 'cloudcover_high', 'cloudcover_low', 'cloudcover_mid', 'cloudcover_total', '10_metre_u_wind_component', '10_metre_v_wind_component', 'forecast_datetime', 'direct_solar_radiation', 'surface_solar_radiation_downwards', 'snowfall', 'total_precipitation']\nhistorical_cols  = ['datetime', 'temperature', 'dewpoint', 'rain', 'snowfall', 'surface_pressure','cloudcover_total','cloudcover_low','cloudcover_mid','cloudcover_high','windspeed_10m','winddirection_10m','shortwave_radiation','direct_solar_radiation','diffuse_radiation','latitude','longitude']\nlocation_cols    = ['longitude', 'latitude', 'county']\ntarget_cols      = ['target', 'county', 'is_business', 'product_type', 'is_consumption', 'datetime']\n\nsave_path = None\nload_path = None\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:17:58.101281Z","iopub.execute_input":"2023-12-08T00:17:58.101653Z","iopub.status.idle":"2023-12-08T00:17:58.109368Z","shell.execute_reply.started":"2023-12-08T00:17:58.101624Z","shell.execute_reply":"2023-12-08T00:17:58.108289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data I/O","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\ndf_data        = pl.read_csv(os.path.join(root, \"train.csv\"), columns=data_cols, try_parse_dates=True)\ndf_client      = pl.read_csv(os.path.join(root, \"client.csv\"), columns=client_cols, try_parse_dates=True)\ndf_gas         = pl.read_csv(os.path.join(root, \"gas_prices.csv\"), columns=gas_cols, try_parse_dates=True)\ndf_electricity = pl.read_csv(os.path.join(root, \"electricity_prices.csv\"), columns=electricity_cols, try_parse_dates=True)\ndf_forecast    = pl.read_csv(os.path.join(root, \"forecast_weather.csv\"), columns=forecast_cols, try_parse_dates=True)\ndf_historical  = pl.read_csv(os.path.join(root, \"historical_weather.csv\"), columns=historical_cols, try_parse_dates=True)\ndf_location    = pl.read_csv(os.path.join(root, \"weather_station_to_county_mapping.csv\"), columns=location_cols, try_parse_dates=True)\ndf_target      = df_data.select(target_cols)\n\nschema_data        = df_data.schema\nschema_client      = df_client.schema\nschema_gas         = df_gas.schema\nschema_electricity = df_electricity.schema\nschema_forecast    = df_forecast.schema\nschema_historical  = df_historical.schema\nschema_target      = df_target.schema\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:18:02.713180Z","iopub.execute_input":"2023-12-08T00:18:02.713972Z","iopub.status.idle":"2023-12-08T00:18:13.644642Z","shell.execute_reply.started":"2023-12-08T00:18:02.713937Z","shell.execute_reply":"2023-12-08T00:18:13.643584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\nX, y = df_data.drop(\"target\"), df_data.select(\"target\")\n\nX = feature_eng(X, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n\ndf_train = to_pandas(X, y)\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:18:29.342017Z","iopub.execute_input":"2023-12-08T00:18:29.343325Z","iopub.status.idle":"2023-12-08T00:18:44.523967Z","shell.execute_reply.started":"2023-12-08T00:18:29.343280Z","shell.execute_reply":"2023-12-08T00:18:44.522566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\ndf_train = df_train[df_train[\"target\"].notnull() & df_train[\"year\"].gt(2021)]\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"execution":{"iopub.status.busy":"2023-12-08T00:18:44.525900Z","iopub.execute_input":"2023-12-08T00:18:44.526326Z","iopub.status.idle":"2023-12-08T00:18:45.132890Z","shell.execute_reply.started":"2023-12-08T00:18:44.526294Z","shell.execute_reply":"2023-12-08T00:18:45.131789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### HyperParam Optimization","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\nbest_params = {\n    'n_iter'           : 900,\n    'verbose'          : -1,\n    'objective'        : 'l2',\n    'learning_rate'    : 0.05689066836106983,\n    'colsample_bytree' : 0.8915976762048253,\n    'colsample_bynode' : 0.5942203285139224,\n    'lambda_l1'        : 3.6277555139102864,\n    'lambda_l2'        : 1.6591278779517808,\n    'min_data_in_leaf' : 186,\n    'max_depth'        : 9,\n    'max_bin'          : 813,\n} # val score is 62.24 for the last month\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\n'''result = cross_validate(\n    estimator=lgb.LGBMRegressor(**best_params, random_state=42),\n    X=df_train.drop(columns=[\"target\"]), \n    y=df_train[\"target\"],\n    scoring=\"neg_mean_absolute_error\",\n    cv=MonthlyKFold(1),\n)\n\nprint(f\"Fit Time(s): {result['fit_time'].mean():.3f}\")\nprint(f\"Score Time(s): {result['score_time'].mean():.3f}\")\nprint(f\"Error(MAE): {-result['test_score'].mean():.3f}\")'''\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------\nif load_path is not None:\n    model = pickle.load(open(load_path, \"rb\"))\nelse:\n    model = VotingRegressor([\n        ('lgb_1', lgb.LGBMRegressor(**best_params, random_state=100)), \n        ('lgb_2', lgb.LGBMRegressor(**best_params, random_state=101)), \n        ('lgb_3', lgb.LGBMRegressor(**best_params, random_state=102)), \n        ('lgb_4', lgb.LGBMRegressor(**best_params, random_state=103)), \n        ('lgb_5', lgb.LGBMRegressor(**best_params, random_state=104)), \n    ])\n    \n    model.fit(\n        X=df_train.drop(columns=[\"target\"]),\n        y=df_train[\"target\"]\n    )\n\nif save_path is not None:\n    with open(save_path, \"wb\") as f:\n        pickle.dump(model, f)\n# ---------------------------------- This is not my work, credit goes to @greysky ---------------------------------","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction","metadata":{}},{"cell_type":"code","source":"import enefit\n\nenv = enefit.make_env()\niter_test = env.iter_test()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (test, revealed_targets, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n    \n    test = test.rename(columns={\"prediction_datetime\": \"datetime\"})\n    \n    df_test           = pl.from_pandas(test[data_cols[1:]], schema_overrides=schema_data)\n    df_client         = pl.from_pandas(client[client_cols], schema_overrides=schema_client)\n    df_gas            = pl.from_pandas(gas_prices[gas_cols], schema_overrides=schema_gas)\n    df_electricity    = pl.from_pandas(electricity_prices[electricity_cols], schema_overrides=schema_electricity)\n    df_new_forecast   = pl.from_pandas(forecast_weather[forecast_cols], schema_overrides=schema_forecast)\n    df_new_historical = pl.from_pandas(historical_weather[historical_cols], schema_overrides=schema_historical)\n    df_new_target     = pl.from_pandas(revealed_targets[target_cols], schema_overrides=schema_target)\n    \n    df_forecast       = pl.concat([df_forecast, df_new_forecast]).unique()\n    df_historical     = pl.concat([df_historical, df_new_historical]).unique()\n    df_target         = pl.concat([df_target, df_new_target]).unique()\n    \n    X_test = feature_eng(df_test, df_client, df_gas, df_electricity, df_forecast, df_historical, df_location, df_target)\n    X_test = to_pandas(X_test)\n    \n    sample_prediction[\"target\"] = model.predict(X_test).clip(0)\n    \n    env.predict(sample_prediction)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}